{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import vgg16, vgg16_bn, resnet18, resnet34, resnet50, resnet101, resnet152\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as skm\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import seaborn as sn\n",
    "\n",
    "from os import listdir, path\n",
    "from PIL import Image\n",
    "from collections import defaultdict\n",
    "import csv\n",
    "import re\n",
    "import os\n",
    "import random\n",
    "\n",
    "from IPython.display import Image as IPython_Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data'\n",
    "IMAGE_PATH = '../data/images'\n",
    "LABEL_PATH = '../data/annotations'\n",
    "\n",
    "# GIVEN DATASET\n",
    "MEAN = (0.43672, 0.40107, 0.36762)\n",
    "STD = (0.30139, 0.28781, 0.29236)\n",
    "       \n",
    "# Define default pos_weights for nn.BCEWithLogitsLoss(pos_weights). These were calculated using\n",
    "# the function calculate_label_statistics (present in notebook 08, but removed from 09 as unnecessary to keep) \n",
    "label_pos_weights_for_loss = np.array([209.52631579, 55.87203791, 58.40594059, 16.77777778, 44.80152672, 5.25, 25.14379085, 5.75675676, 33.09090909, 2.15540363, 5.51465798, 163.38356164, 119., 37.46153846], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_map():\n",
    "    ret = {}\n",
    "\n",
    "    i = 0\n",
    "    for fname in sorted(listdir(LABEL_PATH)):\n",
    "        img_class, _ = fname.split('.')\n",
    "        ret[img_class] = i\n",
    "        i += 1\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(train_fr=.6, max_images_per_class=1e9, LABEL_PATH=LABEL_PATH, IMAGE_PATH=IMAGE_PATH):\n",
    "    \"\"\"\n",
    "    Load data from disk.\n",
    "    \"\"\"\n",
    "    # mapping from class names to integers\n",
    "    class_map = get_class_map()\n",
    "\n",
    "    # create a dictionary to hold our label vectors\n",
    "    n_classes = len(class_map.keys())\n",
    "    img_to_class = defaultdict(lambda: np.zeros(n_classes))\n",
    "\n",
    "    # another dictionary to hold the actual image data\n",
    "    img_to_data = dict()\n",
    "    \n",
    "    # loop through all the annotations\n",
    "    for fname in sorted(listdir(LABEL_PATH)):\n",
    "        img_label, _ = fname.split('.')\n",
    "        img_class = class_map[img_label]\n",
    "        print(f'Reading label: {img_label}, img_class: {img_class}')\n",
    "        \n",
    "        # open the annotation file\n",
    "        i = 0\n",
    "        with open(f'{LABEL_PATH}/{fname}', 'r') as fh:\n",
    "\n",
    "            # get image ids from annotation file\n",
    "            img_ids = fh.read().splitlines()\n",
    "            \n",
    "            # gather the images with labels\n",
    "            for i, img_id in enumerate(img_ids):\n",
    "                \n",
    "                # let's not process images unnecessarily\n",
    "                if not img_id in img_to_data:\n",
    "\n",
    "                    img_path = f'{IMAGE_PATH}/im{img_id}.jpg'\n",
    "                    img = Image.open(img_path)\n",
    "\n",
    "                    # append to dict\n",
    "                    img_to_data[img_id] = img.convert('RGB')\n",
    "\n",
    "                # get one-hot encoded vector of image classes\n",
    "                img_classes = img_to_class[img_id]\n",
    "\n",
    "                # add new class to image vector\n",
    "                img_class = class_map[img_label]\n",
    "                img_classes[img_class] = 1\n",
    "\n",
    "                # store the updated vector back\n",
    "                img_to_class[img_id] = img_classes\n",
    "\n",
    "                if i >= max_images_per_class:\n",
    "                    break\n",
    "\n",
    "                i += 1\n",
    "\n",
    "    # load also all the images that do not have any labels\n",
    "    i = 0\n",
    "    print(f'Reading images without labels..')\n",
    "    for fname in listdir(IMAGE_PATH):\n",
    "        m = re.match('im(\\d+)', fname)\n",
    "        img_id = m.group(1)\n",
    "\n",
    "        if img_id not in img_to_data:\n",
    "            img_path = f'{IMAGE_PATH}/im{img_id}.jpg'\n",
    "            img = Image.open(img_path)\n",
    "\n",
    "            # append to dict\n",
    "            img_to_data[img_id] = img.convert('RGB')\n",
    "\n",
    "            if i >= max_images_per_class:\n",
    "                break\n",
    "\n",
    "            i += 1\n",
    "\n",
    "    print('Creating train/valid/test split..')\n",
    "    \n",
    "    # collect data to a single array\n",
    "    X = []\n",
    "    y = []\n",
    "    for img_id in img_to_data.keys():\n",
    "        X.append(img_to_data[img_id])\n",
    "        y.append(img_to_class[img_id])\n",
    "\n",
    "    if train_fr == 1:\n",
    "        print('Done.')\n",
    "        return X, [], [], y, [], []\n",
    "    \n",
    "    # create train/valid/test split\n",
    "    X_train, X_tmp, y_train, y_tmp = train_test_split(X, y, train_size=train_fr, random_state=42)\n",
    "    X_test, X_valid, y_test, y_valid = train_test_split(X_tmp, y_tmp, train_size=.5, test_size=.5, random_state=42)\n",
    "    \n",
    "    print('Done.')\n",
    "    return X_train, X_valid, X_test, y_train, y_valid, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_data(test_image_path):\n",
    "    \"\"\"\n",
    "    Load the test data provided by University.\n",
    "    \"\"\"\n",
    "    # dictionary to hold the image data\n",
    "    img_to_data = dict()\n",
    "    \n",
    "    # loop through all the test images\n",
    "    i = 0\n",
    "    print(f'Reading test images..')\n",
    "    for fname in listdir(test_image_path):\n",
    "        m = re.match('im(\\d+)', fname)\n",
    "        img_id = m.group(1)\n",
    "\n",
    "        img_path = f'{test_image_path}/im{img_id}.jpg'\n",
    "        img = Image.open(img_path)\n",
    "\n",
    "        # append to dict\n",
    "        img_to_data[img_id] = img.convert('RGB')\n",
    "        i += 1\n",
    "\n",
    "    # collect data to a single array\n",
    "    X = []\n",
    "    for img_id in sorted(img_to_data.keys()):\n",
    "        X.append(img_to_data[img_id])\n",
    "   \n",
    "    print('Done.')\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformingDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Dataset that can perform transformations for\n",
    "    transferring the image to correct format and\n",
    "    data augmentation.\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, transforms=None):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_data = self.X[idx]\n",
    "        img_class = self.y[idx]\n",
    "\n",
    "        if self.transforms:\n",
    "            img_data = self.transforms(img_data)\n",
    "\n",
    "        return img_data, img_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformingTestDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Dataset that can perform transformations for\n",
    "    transferring the image to correct format and\n",
    "    data augmentation.\n",
    "\n",
    "    This dataset is used for test data when we do\n",
    "    not have the ground truth labels.\n",
    "    \"\"\"\n",
    "    def __init__(self, X, transforms=None):\n",
    "        self.X = X\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_data = self.X[idx]\n",
    "\n",
    "        if self.transforms:\n",
    "            img_data = self.transforms(img_data)\n",
    "\n",
    "        return img_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "class OneLayerModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Plain simple feedforward network with one hidden\n",
    "    layer and batch normalization.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_input, n_hidden, n_classes):\n",
    "        super().__init__()\n",
    "        self.input_layer = nn.Linear(n_input, n_hidden)\n",
    "        self.hidden = nn.Linear(n_hidden, n_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.bn0 = nn.BatchNorm1d(n_input)\n",
    "        self.bn1 = nn.BatchNorm1d(n_hidden)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.reshape(-1, 128*128*3)\n",
    "        x = self.bn0(x)\n",
    "        x = self.input_layer(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.hidden(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "class TwoLayerModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Plain simple feedforward network with two hidden\n",
    "    layers and batch normalization.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_input, n_hidden1, n_hidden2, n_classes):\n",
    "        super().__init__()\n",
    "        self.input_layer = nn.Linear(n_input, n_hidden1)\n",
    "        self.hidden1 = nn.Linear(n_hidden1, n_hidden2)\n",
    "        self.hidden2 = nn.Linear(n_hidden2, n_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.bn0 = nn.BatchNorm1d(n_input)\n",
    "        self.bn1 = nn.BatchNorm1d(n_hidden1)\n",
    "        self.bn2 = nn.BatchNorm1d(n_hidden2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.reshape(-1, 128*128*3)\n",
    "        x = self.bn0(x)\n",
    "        x = self.input_layer(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.hidden1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.hidden2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNetModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Convolutional Neural Network from scratch.\n",
    "\n",
    "    For sure, not the most efficient architecture,\n",
    "    but something to test with.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_classes, keep_prob=.5):\n",
    "        super(ConvNetModel, self).__init__()\n",
    "        \n",
    "        # Common layers used multiple times\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.dropout = nn.Dropout(p=1-keep_prob)\n",
    "        \n",
    "        # Unique layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1) #(n samples, channels, height, width)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=392, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(in_features=64*4*392, out_features=14)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.reshape(-1, 3, 128, 128)\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.maxpool(out)\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.maxpool(out)\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        out = self.conv3(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.maxpool(out)\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        out = out.reshape(out.size(0), -1)  # Flatten for FC\n",
    "        out = self.fc1(out)\n",
    "        return out    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "def evaluate(dataloader, model, criterion, device, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Function for evaluating model performance.\n",
    "\n",
    "    Goes through all the data in a dataloader\n",
    "    and reports the mean loss and mean F1 -score.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    f1_scores = []\n",
    "    losses = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            X, y = batch\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            y_pred = torch.sigmoid(model(X))\n",
    "\n",
    "            loss = criterion(y_pred, y)\n",
    "            losses.append(loss)\n",
    "\n",
    "            score = f1_score(y.cpu() == 1, y_pred.cpu() > threshold, average='micro')\n",
    "            f1_scores.append(score)\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    return torch.mean(torch.tensor(losses)), torch.mean(torch.tensor(f1_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "def train(train_dataloader, valid_dataloader, model, optimizer, scheduler, criterion, device, n_epochs=50, verbose=True, threshold=0.5, n_report_fr=10):\n",
    "    \"\"\"\n",
    "    The main training loop.\n",
    "    \"\"\"\n",
    "\n",
    "    model.train()\n",
    "    \n",
    "    train_losses, valid_losses = [], []\n",
    "    train_scores, valid_scores = [], []\n",
    "\n",
    "    fmt = '{:<5} {:12} {:12} {:<9} {:<9}'\n",
    "    print(fmt.format('Epoch', 'Train loss', 'Valid loss', 'Train F1', 'Valid F1'))\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        for i, batch in enumerate(train_dataloader):\n",
    "            X, y = batch\n",
    "            \n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(X)\n",
    "            loss = criterion(y_pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            \n",
    "            if verbose and i % n_report_fr == 0:\n",
    "                print(f'Epoch: {epoch+1}, iteration: {i+1}, loss: {loss}')\n",
    "            \n",
    "        if verbose:            \n",
    "            print(f'Epoch: {epoch+1}, iteration: {i+1}, loss: {loss}')\n",
    "\n",
    "        train_loss, train_score = evaluate(train_dataloader, model, criterion, device, threshold)\n",
    "        valid_loss, valid_score = evaluate(valid_dataloader, model, criterion, device, threshold)\n",
    "        \n",
    "        train_losses.append(train_loss)\n",
    "        train_scores.append(train_score)\n",
    "        valid_losses.append(valid_loss)\n",
    "        valid_scores.append(valid_score)\n",
    "\n",
    "        fmt = '{:<5} {:03.10f} {:03.10f} {:02.7f} {:02.7f}'\n",
    "        print(fmt.format(epoch+1, train_loss, valid_loss, train_score, valid_score))\n",
    "            \n",
    "    print('Done training!')\n",
    "    \n",
    "    return train_losses, valid_losses, train_scores, valid_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_true_positives(img_label, model, device, dataloader, n_to_show=10, threshold=0.75):\n",
    "\n",
    "    class_map = get_class_map()\n",
    "    img_class = class_map[img_label]\n",
    "\n",
    "    def predicate(pred_classes, true_classes):\n",
    "        return True if img_class in pred_classes and img_class in true_classes else False\n",
    "\n",
    "    visualize_predictions(model, device, dataloader, n_to_show=n_to_show, threshold=threshold, predicate=predicate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_true_negatives(img_label, model, device, dataloader, n_to_show=10, threshold=0.75):\n",
    "\n",
    "    class_map = get_class_map()\n",
    "    img_class = class_map[img_label]\n",
    "\n",
    "    def predicate(pred_classes, true_classes):\n",
    "        return True if not img_class in pred_classes and not img_class in true_classes else False\n",
    "\n",
    "    visualize_predictions(model, device, dataloader, n_to_show=n_to_show, threshold=threshold, predicate=predicate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_false_positives(img_label, model, device, dataloader, n_to_show=10, threshold=0.75):\n",
    "\n",
    "    class_map = get_class_map()\n",
    "    img_class = class_map[img_label]\n",
    "\n",
    "    def predicate(pred_classes, true_classes):\n",
    "        return True if img_class in pred_classes and not img_class in true_classes else False\n",
    "\n",
    "    visualize_predictions(model, device, dataloader, n_to_show=n_to_show, threshold=threshold, predicate=predicate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_false_negatives(img_label, model, device, dataloader, n_to_show=10, threshold=0.75):\n",
    "\n",
    "    class_map = get_class_map()\n",
    "    img_class = class_map[img_label]\n",
    "\n",
    "    def predicate(pred_classes, true_classes):\n",
    "        return True if not img_class in pred_classes and img_class in true_classes else False\n",
    "\n",
    "    visualize_predictions(model, device, dataloader, n_to_show=n_to_show, threshold=threshold, predicate=predicate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "def visualize_predictions(model, device, dataloader, mean=MEAN, std=STD, n_to_show=10, threshold=0.5, predicate=None):\n",
    "    \"\"\"\n",
    "    Function to visualize predictions.\n",
    "\n",
    "    Accepts a predicate as a parameter so it can\n",
    "    be adopted to display for example only false\n",
    "    positives or true positives.\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    if predicate == None:\n",
    "        predicate = lambda p1, p2: True\n",
    "\n",
    "    class_to_label = { v: k for k, v in get_class_map().items() }\n",
    "    \n",
    "    n_shown = 0\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        X, y = batch\n",
    "        X = X.to(device)\n",
    "\n",
    "        y_pred = torch.sigmoid(model(X).cpu()) > threshold\n",
    "        y = y == 1\n",
    "        \n",
    "        for i in range(len(y)):\n",
    "            pred_classes = np.where(y_pred[i] == 1)[0]\n",
    "            true_classes = np.where(y[i] == 1)[0]\n",
    "            \n",
    "            if not predicate(pred_classes, true_classes):\n",
    "                continue\n",
    "\n",
    "            show_image_with_predictions(X[i], true_classes, pred_classes)\n",
    "\n",
    "            n_shown += 1\n",
    "            \n",
    "            if n_shown >= n_to_show:\n",
    "                return            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image_with_predictions(X, true_classes, pred_classes, mean=MEAN, std=STD):\n",
    "    \"\"\"\n",
    "    Helper function that just displays an image\n",
    "    in the notebook.\n",
    "    \"\"\"\n",
    "    class_map = get_class_map()\n",
    "    class_to_label = { v: k for k, v in class_map.items() }\n",
    "\n",
    "    true_classes_str = ', '.join([class_to_label[i] for i in true_classes])\n",
    "    pred_classes_str = ', '.join([class_to_label[i] for i in pred_classes])\n",
    "\n",
    "    # https://discuss.pytorch.org/t/simple-way-to-inverse-transform-normalization/4821/5\n",
    "    inv_transform = transforms.Normalize(mean = -1 * np.multiply(mean, std), std=np.divide(1, std))\n",
    "\n",
    "    img = inv_transform(X.cpu()) # inverse transforms\n",
    "    img = img.permute(2, 1, 0)   # BGR -> RGB\n",
    "    img = np.rot90(img, 3)\n",
    "\n",
    "    plt.title(f'True: {true_classes_str}, Predictions: {pred_classes_str}')\n",
    "    plt.imshow(img)\n",
    "    plt.pause(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "def visualize_confusion_matrix(y_true, y_pred, labels, file_path, no_label_cn=None, no_label_score=None):\n",
    "    \"\"\"\n",
    "    Creates an image of confusion matrix on disk.\n",
    "    \"\"\"\n",
    "\n",
    "    plt.ioff()\n",
    "    \n",
    "    # Get confusion matrices\n",
    "    cn_tensor = skm.multilabel_confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Get precision, recall, f1-score\n",
    "    scores = skm.classification_report(y_true, y_pred, output_dict=True)\n",
    "    \n",
    "    # Add non-label scores\n",
    "    if no_label_cn is not None and no_label_score is not None:\n",
    "        cn_tensor = np.concatenate((cn_tensor, no_label_cn[None]), axis=0)\n",
    "        scores['14'] = no_label_score\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=6, ncols=3, sharey=True, figsize=(20, 24), \n",
    "                           gridspec_kw={'hspace': 0.3, 'wspace': 0.0})\n",
    "    gn = ['True Neg','False Pos','False Neg','True Pos']\n",
    "    n = cn_tensor[0].sum()\n",
    "\n",
    "    # Loop all labels\n",
    "    for i, cn_matrix in enumerate(cn_tensor):\n",
    "\n",
    "        j, k = int(i/3), i%3\n",
    "        \n",
    "        # Annotations\n",
    "        annot = np.asarray(\n",
    "            ['{}\\n{:0.0f}\\n{:.2%}'.format(gn[i], x, x/n) for i, x in enumerate(cn_matrix.flatten())]\n",
    "        ).reshape(2,2)\n",
    "        \n",
    "        # Precision, recall, f1-score\n",
    "        title = '{}\\nprec.={:.3}, rec.={:.3}, f1={:.3}'.format(\n",
    "            labels[i], scores[str(i)]['precision'], scores[str(i)]['recall'], scores[str(i)]['f1-score'])\n",
    "        ax[j, k].set_title(title)\n",
    "        ax[j, k].set_ylim([0,2])\n",
    "        \n",
    "        # Plot heatmap\n",
    "        sn.heatmap(cn_matrix, annot=annot, fmt='', cmap='Blues', ax=ax[j, k])\n",
    "        \n",
    "    # Dirty hack: to fix matplotlib and sns incompatibility (positioning annotations)\n",
    "    sn.heatmap(np.array([[0,0],[0,0]]), annot=np.array([['',''],['','']]), fmt='', cmap='Blues', ax=ax[5, 0])\n",
    "        \n",
    "    plt.savefig(file_path, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Fix image size after hack\n",
    "    img = Image.open(file_path).crop((0, 0, 1200, 1150)).save(file_path, 'png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curves(tr_losses, val_losses, tr_scores, val_scores, file_path, title):\n",
    "    \"\"\"\n",
    "    Creates images from arrays containing losses.\n",
    "    \"\"\"\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 4))\n",
    "\n",
    "    ax[0].plot(range(n_epochs), val_losses, label='Validation')\n",
    "    ax[0].plot(range(n_epochs), tr_losses, label='Train')\n",
    "    ax[0].set_title('Loss', fontsize=14)\n",
    "\n",
    "    ax[1].plot(range(n_epochs), val_scores, label='Validation')\n",
    "    ax[1].plot(range(n_epochs), tr_scores, label='Train')\n",
    "    ax[1].set_title('F1-score', fontsize=14)\n",
    "\n",
    "    plt.legend(loc='center', ncol=2, bbox_to_anchor=(-.15, 1.15), fontsize=14)\n",
    "    plt.suptitle(title, fontsize=16, y=1.1)\n",
    "    \n",
    "    # Save learning curve plot\n",
    "    plt.savefig(file_path)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, device, dataloader, threshold=0.70):\n",
    "    \"\"\"\n",
    "    Performs prediction using the given model.\n",
    "\n",
    "    Requires a dataloader that has the images\n",
    "    with labels.\n",
    "    \"\"\"\n",
    "\n",
    "    y_pred = torch.tensor([], device=device, dtype=torch.uint8)\n",
    "    y_true = torch.tensor([], device=device, dtype=torch.uint8)\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            X, y = batch\n",
    "\n",
    "            X = X.to(device)\n",
    "            y = y.to(device).type(torch.uint8)\n",
    "\n",
    "            y_pred_tmp = torch.sigmoid(model(X)) > threshold\n",
    "            y_pred_tmp = y_pred_tmp.type(torch.uint8)\n",
    "\n",
    "            y_pred = torch.cat((y_pred, y_pred_tmp), 0)\n",
    "            y_true = torch.cat((y_true, y), 0)\n",
    "\n",
    "    return y_pred, y_true\n",
    "\n",
    "def predict_testdata(model, device, dataloader, threshold=0.70):\n",
    "    \"\"\"\n",
    "    Performs prediction using the given model.\n",
    "\n",
    "    Works with a dataloader without labels (only images).\n",
    "    \"\"\"\n",
    "    y_pred = torch.tensor([], device=device, dtype=torch.uint8)\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X in dataloader:\n",
    "            X = X.to(device)\n",
    "\n",
    "            y_pred_tmp = torch.sigmoid(model(X)) > threshold\n",
    "            y_pred_tmp = y_pred_tmp.type(torch.uint8)\n",
    "\n",
    "            y_pred = torch.cat((y_pred, y_pred_tmp), 0)\n",
    "\n",
    "    return y_pred\n",
    "\n",
    "def get_prediction_metrics(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates metrics for confusion matrix.\n",
    "    \"\"\"\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    (tn, fp, fn, tp) = tuple(cm.flatten())\n",
    "    \n",
    "    # Precision, recall, f1-score, support\n",
    "    prec, rec, support = tp/(tp+fp), tp/(tp+fn), tp+fn\n",
    "    f1 = 2*prec*rec/(prec+rec)\n",
    "    score = dict([(k, v[1]) for k, v in zip(['precision', 'recall', 'f1-score', 'support'], \n",
    "         precision_recall_fscore_support(y_true, y_pred, average=None))])\n",
    "    \n",
    "    return cm, score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do the magic!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hide_input": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU!\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print('Using GPU!')\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    print('Using CPU')\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "lr = 0.01\n",
    "n_epochs = 25\n",
    "bs = 64\n",
    "n_classes = len(get_class_map().keys())\n",
    "threshold = 0.75\n",
    "#model_name = 'cnn'\n",
    "#model_name = 'ffn1'\n",
    "#model_name = 'ffn2'\n",
    "#model_name = 'vgg16'\n",
    "#model_name = 'vgg16_bn'\n",
    "#model_name = 'resnet18'\n",
    "#model_name = 'resnet34'\n",
    "#model_name = 'resnet50'\n",
    "#model_name = 'resnet50_noaug'\n",
    "model_name = 'resnet50_noaug_dropout'\n",
    "#model_name = 'resnet50_plain'\n",
    "#model_name = 'resnet101'\n",
    "#model_name = 'resnet152'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and save / load dataloaders from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomIndividualApply():\n",
    "    \"\"\"\n",
    "    Custom data augmentation policy.\n",
    "    \n",
    "    Apply randomly a list of transformations with a given probability\n",
    "\n",
    "    Args:\n",
    "        transforms (list or tuple): list of transformations\n",
    "        p (float): probability\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, transforms, p=0.5):\n",
    "        self.p = p\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __call__(self, img):\n",
    "        for t in self.transforms:\n",
    "            if self.p < np.random.random():\n",
    "                continue\n",
    "            img = t(img)\n",
    "        return img\n",
    "\n",
    "    def __repr__(self):\n",
    "        format_string = self.__class__.__name__ + '('\n",
    "        format_string += '\\n    p={}'.format(self.p)\n",
    "        for t in self.transforms:\n",
    "            format_string += '\\n'\n",
    "            format_string += '    {0}'.format(t)\n",
    "        format_string += '\\n)'\n",
    "        return format_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hide_input": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved torch dump from disk.\n",
      " - Done.\n"
     ]
    }
   ],
   "source": [
    "# Create or load dataloaders from disk\n",
    "max_images_per_class = int(1e9)\n",
    "#max_images_per_class = 200\n",
    "\n",
    "transformations = {\n",
    "    'train': transforms.Compose([\n",
    "        RandomIndividualApply([\n",
    "            transforms.RandomHorizontalFlip(p=1),\n",
    "            transforms.RandomRotation((-10, 10)),\n",
    "            transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.3),\n",
    "            transforms.RandomGrayscale(p=0.1),\n",
    "            transforms.RandomPerspective(),\n",
    "        ], p=0.5),\n",
    "        transforms.ToTensor(),                \n",
    "        transforms.Normalize(mean=MEAN, std=STD)            \n",
    "    ]),\n",
    "    'valid': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=MEAN, std=STD)\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=MEAN, std=STD)\n",
    "    ]),\n",
    "}\n",
    "\n",
    "if model_name == 'resnet50_noaug' or model_name == 'resnet50_noaug_dropout':\n",
    "    transformations['train'] = transformations['valid']\n",
    "\n",
    "if not os.path.isfile(f'../data/X_train_n{max_images_per_class}.dat'):\n",
    "    print('Loading all data from disk.')\n",
    "    X_train, X_valid, X_test, y_train, y_valid, y_test = get_data(max_images_per_class=max_images_per_class)\n",
    "    torch.save(X_train, f'../data/X_train_n{max_images_per_class}.dat')\n",
    "    torch.save(X_valid, f'../data/X_valid_n{max_images_per_class}.dat')\n",
    "    torch.save(X_test, f'../data/X_test_n{max_images_per_class}.dat')\n",
    "    torch.save(y_train, f'../data/y_train_n{max_images_per_class}.dat')\n",
    "    torch.save(y_valid, f'../data/y_valid_n{max_images_per_class}.dat')\n",
    "    torch.save(y_test, f'../data/y_test_n{max_images_per_class}.dat')\n",
    "    print(' - Done.')\n",
    "else:\n",
    "    print('Loading saved torch dump from disk.')\n",
    "    X_train = torch.load(f'../data/X_train_n{max_images_per_class}.dat')\n",
    "    X_valid = torch.load(f'../data/X_valid_n{max_images_per_class}.dat')\n",
    "    X_test = torch.load(f'../data/X_test_n{max_images_per_class}.dat')\n",
    "    y_train = torch.load(f'../data/y_train_n{max_images_per_class}.dat')\n",
    "    y_valid = torch.load(f'../data/y_valid_n{max_images_per_class}.dat')\n",
    "    y_test = torch.load(f'../data/y_test_n{max_images_per_class}.dat')\n",
    "    print(' - Done.')\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    TransformingDataset(X_train, y_train, transforms=transformations['train']),\n",
    "    shuffle=True,\n",
    "    batch_size=bs)\n",
    "\n",
    "valid_dataloader = DataLoader(\n",
    "    TransformingDataset(X_valid, y_valid, transforms=transformations['valid']),\n",
    "    shuffle=True,\n",
    "    batch_size=bs)\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    TransformingDataset(X_test, y_test, transforms=transformations['test']),\n",
    "    shuffle=True,\n",
    "    batch_size=bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_name == 'ffn1':\n",
    "    model = OneLayerModel(128*128*3, 128, n_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_name == 'ffn2':\n",
    "    model = TwoLayerModel(128*128*3, 512, 256, n_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_name == 'cnn':\n",
    "    model = ConvNetModel(n_classes=n_classes, keep_prob=.5).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB: The mean and std in transformations most probably need to be the same as for VGG and RESNET. Not 100% sure about this. Something to investigate!\n",
    "\n",
    "From: https://discuss.pytorch.org/t/about-normalization-using-pre-trained-vgg16-networks/23560 \n",
    "*Usually if your use case stays in the same data domain, the mean and std won’t be that different and you can try to use the ImageNet statistics.\n",
    "I would recommend to use your own data statistics if you are dealing with another domain, e.g. medical images.*\n",
    "\n",
    "\n",
    "More models here: https://pytorch.org/docs/stable/torchvision/models.html\n",
    "\n",
    "If the models do not start to converge, try lowering the learning rate!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_VGG16_\n",
    "\n",
    "Currently getting validation f1 scores around 0.67. \n",
    "\n",
    "Now around 0.71 with one cycle policy.\n",
    "\n",
    "Surprisingly after quick testing the vgg16_bn (with BatchNorm layers) did not do as well? Maybe more to investigate here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_name == 'vgg16' or model_name == 'vgg16_bn':\n",
    "    \n",
    "    if model_name == 'vgg16':\n",
    "        model = vgg16(pretrained=True).to(device)\n",
    "    else:\n",
    "        model = vgg16_bn(pretrained=True).to(device)\n",
    "\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Linear(25088, 4096),\n",
    "        nn.ReLU(),\n",
    "        #nn.Dropout(p=.5),\n",
    "        nn.Linear(4096, 2048),\n",
    "        nn.ReLU(),\n",
    "        #nn.Dropout(p=.2),\n",
    "        nn.Linear(2048, 14),\n",
    "    ).to(device)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_RESNET_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_name == 'resnet18':\n",
    "    model = resnet18(pretrained=True).to(device)\n",
    "\n",
    "    for layer in model.children():\n",
    "        layer.requires_grad = False\n",
    "\n",
    "    model.fc = nn.Linear(512, 14).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_name == 'resnet34':\n",
    "    model = resnet34(pretrained=True).to(device)\n",
    "\n",
    "    for layer in model.children():\n",
    "        layer.requires_grad = False\n",
    "\n",
    "    model.fc = nn.Linear(512, 14).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using dropout\n"
     ]
    }
   ],
   "source": [
    "if model_name == 'resnet50' or model_name == 'resnet50_noaug' or model_name == 'resnet50_noaug_dropout':\n",
    "    model = resnet50(pretrained=True).to(device)\n",
    "    \n",
    "    if model_name == 'resnet50_noaug_dropout':\n",
    "        print('Using dropout')\n",
    "        model.fc.register_forward_hook(lambda m, inp, out: F.dropout(out, p=0.5, training=m.training))\n",
    "\n",
    "    for layer in model.children():\n",
    "        layer.requires_grad = False\n",
    "\n",
    "    model.fc = nn.Linear(2048, 14).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_name == 'resnet101':\n",
    "    model = resnet101(pretrained=True).to(device)\n",
    "\n",
    "    for layer in model.children():\n",
    "        layer.requires_grad = False\n",
    "\n",
    "    model.fc = nn.Linear(2048, 14).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_name == 'resnet152':\n",
    "    model = resnet152(pretrained=True).to(device)\n",
    "\n",
    "    for layer in model.children():\n",
    "        layer.requires_grad = False\n",
    "\n",
    "    model.fc = nn.Linear(2048, 14).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model or load an existing model from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer, loss function and shedueler\n",
    "\n",
    "# loss function\n",
    "pos_weight = torch.from_numpy(label_pos_weights_for_loss).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "# learning rate and momentum will be overriden by the scheduler\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, nesterov=True)\n",
    "\n",
    "# scheduler\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=0.01,\n",
    "    base_momentum=0.5,\n",
    "    max_momentum=0.95,\n",
    "    steps_per_epoch=len(train_dataloader),\n",
    "    epochs=n_epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform training!\n",
    "%time tr_losses, val_losses, tr_scores, val_scores = \\\n",
    "    train(train_dataloader, valid_dataloader,\\\n",
    "          model, optimizer, scheduler, criterion, device,\\\n",
    "          n_epochs=n_epochs, verbose=False, threshold=threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model performance.\n",
    "avg_loss, avg_f1 = evaluate(valid_dataloader, model, criterion, device, threshold=threshold)\n",
    "print(f'Threshold {threshold}: mean loss {avg_f1:.3}, mean F1-score {avg_f1:.3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a model on disk to continue training later\n",
    "if True:\n",
    "    model_whole_save_path = f'../data/{model_name}-epochs{n_epochs}-bs{bs}-valid-F1-{avg_f1:.3}.pth'\n",
    "    print(f'Saving model to {model_whole_save_path}')\n",
    "    torch.save(model, model_whole_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning curve\n",
    "if True:\n",
    "    title = f'Learning curves for model `{model_name}`, batch size {bs}, epochs {n_epochs}'\n",
    "    file_path = f'../results/{model_name}-epochs{n_epochs}-bs{bs}-valid-F1-{avg_f1:.3}_learningcurve.png'\n",
    "    plot_learning_curves(tr_losses, val_losses, tr_scores, val_scores, file_path, title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is for finding the optimal threshold.\n",
    "if False:\n",
    "    f1_scores = []\n",
    "    for threshold in np.arange(0.05, 1, 0.05):\n",
    "        _, f1 = evaluate(valid_dataloader, model, criterion, device, threshold=threshold)\n",
    "        f1_scores.append(f1)\n",
    "        print(f'threshold: {threshold}, f1 score: {f1}')\n",
    "\n",
    "    plt.plot(np.arange(0.05, 1, 0.05), f1_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show some images with predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    visualize_predictions(model, device, test_dataloader, n_to_show=5, threshold=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TP/FP/TN/FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.65\n",
    "visualize_tpfptnfn = False\n",
    "img_label = 'baby'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if visualize_tpfptnfn:\n",
    "    visualize_false_positives(img_label, model, device, valid_dataloader, threshold=threshold, n_to_show=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if visualize_tpfptnfn:\n",
    "    visualize_false_negatives(img_label, model, device, valid_dataloader, threshold=threshold, n_to_show=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if visualize_tpfptnfn:\n",
    "    visualize_true_positives(img_label, model, device, valid_dataloader, threshold=threshold, n_to_show=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if visualize_tpfptnfn:\n",
    "    visualize_true_negatives(img_label, model, device, valid_dataloader, threshold=threshold, n_to_show=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict and evaluate using our own test data\n",
    "\n",
    "## Load our best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('../data/resnet50-epochs25-bs64-valid-F1-0.74.pth')\n",
    "model_name = 'resnet50'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    model_name = 'resnet152_plain'\n",
    "    model = resnet152(pretrained=True).to(device)\n",
    "\n",
    "    for layer in model.children():\n",
    "        layer.requires_grad = False\n",
    "\n",
    "    model.fc = nn.Linear(2048, 14).to(device)\n",
    "    model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict using our own test data using ```test_dataloader``` (already loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Predict \n",
    "y_true, y_pred = predict(model, device, test_dataloader, threshold=threshold)\n",
    "y_true, y_pred = y_true.cpu().numpy(), y_pred.cpu().numpy()\n",
    "\n",
    "# Save results to disk\n",
    "path_pred, path_true = f'../results/{model_name}_pred.txt', f'../results/{model_name}_true.txt'\n",
    "np.savetxt(path_pred, y_pred, fmt='%d')\n",
    "np.savetxt(path_true, y_true, fmt='%d')\n",
    "print(f'Saved results in {path_pred}, {path_true}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run test_eval.py against our own test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"../scripts/test_eval.py\" $path_pred $path_true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification report for our own test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save classification report\n",
    "with open(f'../results/{model_name}_classification_report.txt', 'w') as file:\n",
    "    file.write(skm.classification_report(y_true, y_pred))\n",
    "    \n",
    "# Show classification report\n",
    "with open(f'../results/{model_name}_classification_report.txt', 'r') as file:\n",
    "    report = ''.join(file.readlines())\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix plot for our own test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save confusion matrix plot\n",
    "labels = [k for k, v in get_class_map().items()] + ['unlabelled']\n",
    "\n",
    "#tn, fp, fn, tp = 3750, 157, 21, 72\n",
    "#y_true_no = [0]*tn + [0]*fp + [1]*fn + [1]*tp\n",
    "#y_pred_no = [0]*tn + [1]*fp + [0]*fn + [1]*tp\n",
    "\n",
    "# images and predictions that have no labels\n",
    "y_true_no = (np.sum(y_true, axis=1) == 0).astype(int)\n",
    "y_pred_no = (np.sum(y_pred, axis=1) == 0).astype(int)\n",
    "\n",
    "# confusion matrix and scores for non-labelled images\n",
    "cm, score = get_prediction_metrics(y_true_no, y_pred_no)\n",
    "\n",
    "visualize_confusion_matrix(y_true, y_pred, labels, f'../results/{model_name}_confusion_matrix.png', \n",
    "                           no_label_cn=cm, no_label_score=score)\n",
    "\n",
    "# Show confusion matrix plot\n",
    "IPython_Image(filename=f'../results/{model_name}_confusion_matrix.png', width=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load our best pre-trained model from disk to continue training on validation and test set\n",
    "model = torch.load('../data/resnet152-epochs25-bs64-valid-F1-0.76.pth')\n",
    "model_name = 'resnet152_train'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add our validation and test data and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 1\n",
    "\n",
    "if False:\n",
    "    \n",
    "    model_name = 'resnet152_train_valid'\n",
    "    \n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer,max_lr=0.01, base_momentum=0.5, max_momentum=0.95, \n",
    "        steps_per_epoch=len(valid_dataloader), \n",
    "        epochs=n_epochs,)\n",
    "\n",
    "    _, _, _, _, = train(valid_dataloader, valid_dataloader,\\\n",
    "        model, optimizer, scheduler, criterion, device,\\\n",
    "        n_epochs=n_epochs, verbose=False, threshold=threshold)\n",
    "    \n",
    "if True:\n",
    "    \n",
    "    model_name = 'resnet152_final'\n",
    "    \n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer,max_lr=0.01, base_momentum=0.5, max_momentum=0.95, \n",
    "        steps_per_epoch=len(valid_dataloader), \n",
    "        epochs=n_epochs,)\n",
    "\n",
    "    _, _, _, _, = train(valid_dataloader, valid_dataloader,\\\n",
    "        model, optimizer, scheduler, criterion, device,\\\n",
    "        n_epochs=n_epochs, verbose=False, threshold=threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict \n",
    "y_true, y_pred = predict(model, device, test_dataloader, threshold=threshold)\n",
    "y_true, y_pred = y_true.cpu().numpy(), y_pred.cpu().numpy()\n",
    "\n",
    "# Save results to disk\n",
    "path_pred, path_true = f'../results/{model_name}_pred.txt', f'../results/{model_name}_true.txt'\n",
    "np.savetxt(path_pred, y_pred, fmt='%d')\n",
    "np.savetxt(path_true, y_true, fmt='%d')\n",
    "print(f'Saved results in {path_pred}, {path_true}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"../scripts/test_eval.py\" $path_pred $path_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a model on disk to continue training later\n",
    "if True:\n",
    "    model_whole_save_path = f'../data/resnet152-epochs27-bs64-valid-F1-0.75.pth'\n",
    "    print(f'Saving model to {model_whole_save_path}')\n",
    "    torch.save(model, model_whole_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict and evaluate using actual test data\n",
    "\n",
    "## Load our final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('../data/resnet152-epochs27-bs64-valid-F1-0.75.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data paths for actual test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH2 = '../test_data'\n",
    "#DATA_PATH2 = '../data'\n",
    "IMAGE_PATH2 = f'{DATA_PATH2}/images'\n",
    "LABEL_PATH2 = f'{DATA_PATH2}/annotations'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load actual test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load actual testset\n",
    "if not os.path.isfile(f'{DATA_PATH2}/X_test_actual.dat'):\n",
    "    print('Loading test data from disk.')\n",
    "    \n",
    "    # Use this when we have the actual test data: get the whole test data in one dataloader\n",
    "    X_test_actual = get_test_data(test_image_path = IMAGE_PATH2)\n",
    "    \n",
    "    torch.save(X_test_actual, f'{DATA_PATH2}/X_test_actual.dat')\n",
    "else:\n",
    "    print('Loading saved torch dump of test images from disk.')\n",
    "    X_test_actual = torch.load(f'{DATA_PATH2}/X_test_actual.dat')    \n",
    "\n",
    "test_dataloader_actual = DataLoader(\n",
    "    TransformingTestDataset(X_test_actual, transforms=transformations['test']),\n",
    "    shuffle=False,\n",
    "    batch_size=bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict for actual test data and save predictions on disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict \n",
    "y_pred = predict_testdata(model, device, test_dataloader_actual, threshold=threshold)\n",
    "\n",
    "# Save results to disk\n",
    "path_pred_actual = f'../results/{model_name}_actual_pred.txt'\n",
    "np.savetxt(path_pred_actual, y_pred.cpu(), fmt='%d')\n",
    "print(f'Saved actual test data results in {path_pred_actual}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run test_eval.py using actual test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"../scripts/test_eval.py\" $path_pred_actual $path_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
