{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.models import vgg16, vgg16_bn, resnet18, resnet34, resnet50, resnet101, resnet152\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as skm\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import seaborn as sn\n",
    "\n",
    "from os import listdir, path\n",
    "from PIL import Image\n",
    "from collections import defaultdict\n",
    "import csv\n",
    "import re\n",
    "import os\n",
    "\n",
    "from IPython.display import display, clear_output, Image as IPython_Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PATH = '../data/images'\n",
    "LABEL_PATH = '../data/annotations'\n",
    "\n",
    "# GIVEN DATASET\n",
    "MEAN = (0.43672, 0.40107, 0.36762)\n",
    "STD = (0.30139, 0.28781, 0.29236)\n",
    "\n",
    "# IMAGENET\n",
    "#MEAN = (0.485, 0.456, 0.406)\n",
    "#STD = (0.229, 0.224, 0.225)\n",
    "\n",
    "# RESNET\n",
    "#MEAN = (0.485, 0.456, 0.406)\n",
    "#STD = (0.229, 0.224, 0.225)\n",
    "       \n",
    "# Define default pos_weights for nn.BCEWithLogitsLoss(pos_weights).\n",
    "label_pos_weights_for_loss = np.array([209.52631579, 55.87203791, 58.40594059, 16.77777778, 44.80152672, 5.25, 25.14379085, 5.75675676, 33.09090909, 2.15540363, 5.51465798, 163.38356164, 119., 37.46153846], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_classes():\n",
    "    return len(listdir(LABEL_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_map():\n",
    "    ret = {}\n",
    "\n",
    "    i = 0\n",
    "    for fname in sorted(listdir(LABEL_PATH)):\n",
    "        img_class, _ = fname.split('.')\n",
    "        ret[img_class] = i\n",
    "        i += 1\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_labels_to_csv(name_of_set, label_array):\n",
    "    filepath = f'../data/labels_{name_of_set}.csv'\n",
    "    \n",
    "    label_arr = np.array(label_array).astype(int)\n",
    "\n",
    "    # Save 2D numpy array to csv file\n",
    "    np.savetxt(filepath, label_arr, delimiter=',', fmt='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(train_fr=.6, max_images_per_class=1e9, LABEL_PATH=LABEL_PATH, IMAGE_PATH=IMAGE_PATH):\n",
    "    \n",
    "    # mapping from class names to integers\n",
    "    class_map = get_class_map()\n",
    "\n",
    "    # create a dictionary to hold our label vectors\n",
    "    n_classes = len(class_map.keys())\n",
    "    img_to_class = defaultdict(lambda: np.zeros(n_classes))\n",
    "\n",
    "    # another dictionary to hold the actual image data\n",
    "    img_to_data = dict()\n",
    "    \n",
    "    # loop through all the annotations\n",
    "    for fname in sorted(listdir(LABEL_PATH)):\n",
    "        img_class, _ = fname.split('.')\n",
    "        print(f'Reading class: {img_class}')\n",
    "        \n",
    "        # open the annotation file\n",
    "        i = 0\n",
    "        with open(f'{LABEL_PATH}/{fname}', 'r') as fh:\n",
    "\n",
    "            # get image ids from annotation file\n",
    "            img_ids = fh.read().splitlines()\n",
    "            \n",
    "            # gather the images with labels\n",
    "            for i, img_id in enumerate(img_ids):\n",
    "                \n",
    "                # let's not process images unnecessarily\n",
    "                if not img_id in img_to_data:\n",
    "\n",
    "                    img_path = f'{IMAGE_PATH}/im{img_id}.jpg'\n",
    "                    img = Image.open(img_path)\n",
    "\n",
    "                    # append to dict\n",
    "                    img_to_data[img_id] = img.convert('RGB')\n",
    "\n",
    "                # get one-hot encoded vector of image classes\n",
    "                img_classes = img_to_class[img_id]\n",
    "\n",
    "                # add new class to image vector\n",
    "                img_class_id = class_map[img_class]\n",
    "                img_classes[img_class_id] = 1\n",
    "\n",
    "                # store the updated vector back\n",
    "                img_to_class[img_id] = img_classes\n",
    "\n",
    "                if i >= max_images_per_class:\n",
    "                    break\n",
    "\n",
    "                i += 1\n",
    "\n",
    "    # load also all the images that do not have any labels\n",
    "    i = 0\n",
    "    print(f'Reading images without labels..')\n",
    "    for fname in listdir(IMAGE_PATH):\n",
    "        m = re.match('im(\\d+)', fname)\n",
    "        img_id = m.group(1)\n",
    "\n",
    "        if img_id not in img_to_data:\n",
    "            img_path = f'{IMAGE_PATH}/im{img_id}.jpg'\n",
    "            img = Image.open(img_path)\n",
    "\n",
    "            # append to dict\n",
    "            img_to_data[img_id] = img.convert('RGB')\n",
    "\n",
    "            if i >= max_images_per_class:\n",
    "                break\n",
    "\n",
    "            i += 1\n",
    "\n",
    "    print('Creating train/valid/test split..')\n",
    "    # collect data to a single array\n",
    "    X = []\n",
    "    y = []\n",
    "    for img_id in img_to_data.keys():\n",
    "        X.append(img_to_data[img_id])\n",
    "        y.append(img_to_class[img_id])\n",
    "\n",
    "    if train_fr == 1:\n",
    "        print('Done.')\n",
    "        return X, y, [], [], [], []\n",
    "        \n",
    "    X_train, X_tmp, y_train, y_tmp = train_test_split(X, y, train_size=train_fr, random_state=42)\n",
    "    X_test, X_valid, y_test, y_valid = train_test_split(X_tmp, y_tmp, train_size=.5, test_size=.5, random_state=42)\n",
    "    \n",
    "    print('Done.')\n",
    "    return X_train, X_valid, X_test, y_train, y_valid, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformingDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y, transforms=None):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_data = self.X[idx]\n",
    "        img_class = self.y[idx]\n",
    "\n",
    "        if transforms:\n",
    "            img_data = self.transforms(img_data)\n",
    "\n",
    "        return img_data, img_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "class TwoLayerModel(nn.Module):\n",
    "    def __init__(self, n_input, n_hidden1, n_hidden2, n_classes):\n",
    "        super().__init__()\n",
    "        self.bs = bs\n",
    "        self.input_layer = nn.Linear(n_input, n_hidden1)\n",
    "        self.hidden1 = nn.Linear(n_hidden1, n_hidden2)\n",
    "        self.hidden2 = nn.Linear(n_hidden2, n_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.bn0 = nn.BatchNorm1d(n_input)\n",
    "        self.bn1 = nn.BatchNorm1d(n_hidden1)\n",
    "        self.bn2 = nn.BatchNorm1d(n_hidden2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.bn0(x)\n",
    "        x = self.input_layer(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.hidden1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.hidden2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "class OneLayerModel(nn.Module):\n",
    "    def __init__(self, n_input, n_hidden, n_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_layer = nn.Linear(n_input, n_hidden)\n",
    "        self.hidden = nn.Linear(n_hidden, n_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.bn0 = nn.BatchNorm1d(n_input)\n",
    "        self.bn1 = nn.BatchNorm1d(n_hidden)\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(f'X.SHAPE: {x.shape}')\n",
    "        x = self.bn0(x)\n",
    "        x = self.input_layer(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.hidden(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "class ConvNetModel(nn.Module):\n",
    "    def __init__(self, n_classes, keep_prob=.5):\n",
    "        super(ConvNetModel, self).__init__()\n",
    "        # Common layers used multiple times\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.dropout = nn.Dropout(p=1-keep_prob)\n",
    "        \n",
    "        # Unique layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=256, kernel_size=3, stride=1, padding=1) #(n samples, channels, height, width)\n",
    "        self.conv2 = nn.Conv2d(in_channels=256, out_channels=14, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc3 = nn.Linear(in_features=256*4*14, out_features=n_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.reshape(-1, 3, 128, 128)\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.maxpool(out)\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.maxpool(out)\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        out = out.reshape(out.size(0), -1)  # Flatten for FC\n",
    "        out = self.fc3(out)\n",
    "        return out    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "def evaluate(dataloader, model, criterion, device, threshold=0.5):\n",
    "    model.eval()\n",
    "\n",
    "    f1_scores = []\n",
    "    losses = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            X, y = batch\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            y_pred = model(X)\n",
    "\n",
    "            loss = criterion(y_pred, y)\n",
    "            losses.append(loss)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                score = f1_score(y.cpu() == 1, y_pred.cpu() > threshold, average='micro')\n",
    "                f1_scores.append(score)\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    return torch.mean(torch.tensor(losses)), torch.mean(torch.tensor(f1_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "def train(train_dataloader, valid_dataloader, model, optimizer, scheduler, criterion, device, n_epochs=50, verbose=True, threshold=0.5, n_report_fr=10):\n",
    "    model.train()\n",
    "    \n",
    "    train_losses, valid_losses = [], []\n",
    "    train_scores, valid_scores = [], []\n",
    "\n",
    "    fmt = '{:<5} {:12} {:12} {:<9} {:<9}'\n",
    "    print(fmt.format('Epoch', 'Train loss', 'Valid loss', 'Train F1', 'Valid F1'))\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        for i, batch in enumerate(train_dataloader):\n",
    "            X, y = batch\n",
    "            \n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(X)\n",
    "            loss = criterion(y_pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            \n",
    "            if verbose and i % n_report_fr == 0:\n",
    "                print(f'Epoch: {epoch+1}, iteration: {i+1}, loss: {loss}')\n",
    "            \n",
    "        if verbose:            \n",
    "            print(f'Epoch: {epoch+1}, iteration: {i+1}, loss: {loss}')\n",
    "\n",
    "        train_loss, train_score = evaluate(train_dataloader, model, criterion, device, threshold)\n",
    "        valid_loss, valid_score = evaluate(valid_dataloader, model, criterion, device, threshold)\n",
    "        \n",
    "        train_losses.append(train_loss)\n",
    "        train_scores.append(train_score)\n",
    "        valid_losses.append(valid_loss)\n",
    "        valid_scores.append(valid_score)\n",
    "\n",
    "        fmt = '{:<5} {:03.10f} {:03.10f} {:02.7f} {:02.7f}'\n",
    "        print(fmt.format(epoch+1, train_loss, valid_loss, train_score, valid_score))\n",
    "            \n",
    "    print('Done training!')\n",
    "    \n",
    "    return train_losses, valid_losses, train_scores, valid_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_true_positives(img_label, model, device, dataloader, n_to_show=10, threshold=0.75):\n",
    "\n",
    "    class_map = get_class_map()\n",
    "    img_class = class_map[img_label]\n",
    "\n",
    "    def predicate(pred_classes, true_classes):\n",
    "        return True if img_class in pred_classes and img_class in true_classes else False\n",
    "\n",
    "    visualize_predictions(model, device, dataloader, n_to_show=n_to_show, predicate=predicate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_true_negatives(img_label, model, device, dataloader, n_to_show=10, threshold=0.75):\n",
    "\n",
    "    class_map = get_class_map()\n",
    "    img_class = class_map[img_label]\n",
    "\n",
    "    def predicate(pred_classes, true_classes):\n",
    "        return True if not img_class in pred_classes and not img_class in true_classes else False\n",
    "\n",
    "    visualize_predictions(model, device, dataloader, n_to_show=n_to_show, predicate=predicate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_false_positives(img_label, model, device, dataloader, n_to_show=10, threshold=0.75):\n",
    "\n",
    "    class_map = get_class_map()\n",
    "    img_class = class_map[img_label]\n",
    "\n",
    "    def predicate(pred_classes, true_classes):\n",
    "        return True if img_class in pred_classes and not img_class in true_classes else False\n",
    "\n",
    "    visualize_predictions(model, device, dataloader, n_to_show=n_to_show, predicate=predicate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_false_negatives(img_label, model, device, dataloader, n_to_show=10, threshold=0.75):\n",
    "\n",
    "    class_map = get_class_map()\n",
    "    img_class = class_map[img_label]\n",
    "\n",
    "    def predicate(pred_classes, true_classes):\n",
    "        return True if not img_class in pred_classes and img_class in true_classes else False\n",
    "\n",
    "    visualize_predictions(model, device, dataloader, n_to_show=n_to_show, predicate=predicate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "def visualize_predictions(model, device, dataloader, mean=MEAN, std=STD, n_to_show=10, threshold=0.5, predicate=None):\n",
    "    \n",
    "    if predicate == None:\n",
    "        predicate = lambda p1, p2: True\n",
    "\n",
    "    class_to_label = { v: k for k, v in get_class_map().items() }\n",
    "    \n",
    "    # https://discuss.pytorch.org/t/simple-way-to-inverse-transform-normalization/4821/5\n",
    "    inv_transform = transforms.Compose([\n",
    "        transforms.Normalize(mean = -1 * np.multiply(mean, std), std=np.divide(1, std))\n",
    "    ])\n",
    "    \n",
    "    n_shown = 0\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        X, y = batch\n",
    "        X = X.to(device)\n",
    "\n",
    "        y_pred_raw = model(X).cpu()\n",
    "        y_pred = y_pred_raw > threshold \n",
    "        y = y == 1\n",
    "        \n",
    "        for i in range(len(y)):\n",
    "            pred_classes = np.where(y_pred[i] == 1)[0]\n",
    "            true_classes = np.where(y[i] == 1)[0]\n",
    "            \n",
    "            if not predicate(pred_classes, true_classes):\n",
    "                continue\n",
    "\n",
    "            show_image_with_predictions(X[i], true_classes, pred_classes)\n",
    "\n",
    "            n_shown += 1\n",
    "            \n",
    "            if n_shown >= n_to_show:\n",
    "                return            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image_with_predictions(X, true_classes, pred_classes, mean=MEAN, std=STD):\n",
    "    \n",
    "    class_map = get_class_map()\n",
    "    class_to_label = { v: k for k, v in class_map.items() }\n",
    "\n",
    "    true_classes_str = ', '.join([class_to_label[i] for i in true_classes])\n",
    "    pred_classes_str = ', '.join([class_to_label[i] for i in pred_classes])\n",
    "\n",
    "    # https://discuss.pytorch.org/t/simple-way-to-inverse-transform-normalization/4821/5\n",
    "    inv_transform = transforms.Normalize(mean = -1 * np.multiply(mean, std), std=np.divide(1, std))\n",
    "\n",
    "    img = inv_transform(X.cpu()) # inverse transforms\n",
    "    img = img.permute(2, 1, 0)   # BGR -> RGB\n",
    "    img = np.rot90(img, 3)\n",
    "\n",
    "    plt.title(f'True: {true_classes_str}, Predictions: {pred_classes_str}')\n",
    "    plt.imshow(img)\n",
    "    plt.pause(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "def predict_X(fr, threshold=0.5):\n",
    "    \n",
    "    y_hat = fr > threshold\n",
    "    \n",
    "    return y_hat if (np.sum(y_hat) > 0) else fr == np.max(fr)\n",
    "\n",
    "def predict(model, device, dataloader):\n",
    "    \n",
    "    ys_all = []  # Array of np.array(14) \n",
    "    y_hats_all = []\n",
    "    \n",
    "    for i, batch in enumerate(dataloader):\n",
    "        \n",
    "        Xs, ys = batch\n",
    "        Xs = model(Xs.to(device))\n",
    "        y_hats = np.apply_along_axis(predict_X, axis=1, arr=Xs.cpu().detach().numpy())\n",
    "        \n",
    "        y_hats_all.extend(y_hat for y_hat in y_hats)\n",
    "        ys_all.extend(y.numpy() for y in ys==1)\n",
    "\n",
    "    return np.array(ys_all), np.array(y_hats_all)\n",
    "\n",
    "def visualize_confusion_matrix(y_true, y_pred, labels, file_path):\n",
    "\n",
    "    plt.ioff()\n",
    "    \n",
    "    # Get confusion matrices\n",
    "    cn_tensor = skm.multilabel_confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Get precision, recall, f1-score\n",
    "    scores = skm.classification_report(y_true, y_pred, output_dict=True)\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=5, ncols=3,sharey=True, figsize=(20, 20), \n",
    "                           gridspec_kw={'hspace': 0.3, 'wspace': 0.0})\n",
    "    gn = ['True Neg','False Pos','False Neg','True Pos']\n",
    "    n = cn_tensor[0].sum()\n",
    "    \n",
    "    # Loop all labels\n",
    "    for i, cn_matrix in enumerate(cn_tensor):\n",
    "\n",
    "        j, k = int(i/3), i%3\n",
    "        \n",
    "        # Annotations\n",
    "        annot = np.asarray(\n",
    "            ['{}\\n{:0.0f}\\n{:.2%}'.format(gn[i], x, x/n) for i, x in enumerate(cn_matrix.flatten())]\n",
    "        ).reshape(2,2)\n",
    "        \n",
    "        # Plot heatmap\n",
    "        sn.heatmap(cn_matrix, annot=annot, fmt='', cmap='Blues', ax=ax[j, k])\n",
    "        \n",
    "        # Precision, recall, f1-score\n",
    "        title = '{}\\nprec.={:.3}, rec.={:.3}, f1={:.3}'.format(\n",
    "            labels[i], scores[str(i)]['precision'], scores[str(i)]['recall'], scores[str(i)]['f1-score'])\n",
    "        ax[j, k].set_title(title)\n",
    "        \n",
    "    plt.savefig(file_path, bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do the magic!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print('Using GPU!')\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    print('Using CPU')\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "lr = 0.01\n",
    "n_epochs = 25\n",
    "bs = 64\n",
    "n_classes = len(get_class_map().keys())\n",
    "threshold = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and save / load dataloaders from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomIndividualApply():\n",
    "    \"\"\"Apply randomly a list of transformations with a given probability\n",
    "\n",
    "    Args:\n",
    "        transforms (list or tuple): list of transformations\n",
    "        p (float): probability\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, transforms, p=0.5):\n",
    "        self.p = p\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __call__(self, img):\n",
    "        for t in self.transforms:\n",
    "            if self.p < np.random.random():\n",
    "                continue\n",
    "            img = t(img)\n",
    "        return img\n",
    "\n",
    "    def __repr__(self):\n",
    "        format_string = self.__class__.__name__ + '('\n",
    "        format_string += '\\n    p={}'.format(self.p)\n",
    "        for t in self.transforms:\n",
    "            format_string += '\\n'\n",
    "            format_string += '    {0}'.format(t)\n",
    "        format_string += '\\n)'\n",
    "        return format_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "#max_images_per_class = int(1e9)\n",
    "max_images_per_class = 10\n",
    "\n",
    "transformations = {\n",
    "    'train': transforms.Compose([\n",
    "        RandomIndividualApply([\n",
    "            transforms.RandomHorizontalFlip(p=1),\n",
    "            transforms.RandomRotation((-10, 10)),\n",
    "            transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.3),\n",
    "            transforms.RandomGrayscale(p=0.1),\n",
    "            transforms.RandomPerspective(),\n",
    "        ], p=0.5),\n",
    "        transforms.ToTensor(),                \n",
    "        transforms.Normalize(mean=MEAN, std=STD)            \n",
    "    ]),\n",
    "    'valid': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=MEAN, std=STD)\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=MEAN, std=STD)\n",
    "    ]),\n",
    "}\n",
    "\n",
    "if not os.path.isfile(f'../data/X_train_n{max_images_per_class}.dat'):\n",
    "    print('Loading all data from disk.')\n",
    "    X_train, X_valid, X_test, y_train, y_valid, y_test = get_data(max_images_per_class=max_images_per_class)\n",
    "    torch.save(X_train, f'../data/X_train_n{max_images_per_class}.dat')\n",
    "    torch.save(X_valid, f'../data/X_valid_n{max_images_per_class}.dat')\n",
    "    torch.save(X_test, f'../data/X_test_n{max_images_per_class}.dat')\n",
    "    torch.save(y_train, f'../data/y_train_n{max_images_per_class}.dat')\n",
    "    torch.save(y_valid, f'../data/y_valid_n{max_images_per_class}.dat')\n",
    "    torch.save(y_test, f'../data/y_test_n{max_images_per_class}.dat')\n",
    "    print(' - Done.')\n",
    "else:\n",
    "    print('Loading saved torch dump from disk.')\n",
    "    X_train = torch.load(f'../data/X_train_n{max_images_per_class}.dat')\n",
    "    X_valid = torch.load(f'../data/X_valid_n{max_images_per_class}.dat')\n",
    "    X_test = torch.load(f'../data/X_test_n{max_images_per_class}.dat')\n",
    "    y_train = torch.load(f'../data/y_train_n{max_images_per_class}.dat')\n",
    "    y_valid = torch.load(f'../data/y_valid_n{max_images_per_class}.dat')\n",
    "    y_test = torch.load(f'../data/y_test_n{max_images_per_class}.dat')\n",
    "    print(' - Done.')\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    TransformingDataset(X_train, y_train, transforms=transformations['train']),\n",
    "    shuffle=True,\n",
    "    batch_size=bs)\n",
    "\n",
    "valid_dataloader = DataLoader(\n",
    "    TransformingDataset(X_valid, y_valid, transforms=transformations['valid']),\n",
    "    shuffle=True,\n",
    "    batch_size=bs)\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    TransformingDataset(X_test, y_test, transforms=transformations['test']),\n",
    "    shuffle=True,\n",
    "    batch_size=bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB: The mean and std in transformations most probably need to be the same as for VGG and RESNET. Not 100% sure about this. Something to investigate!\n",
    "\n",
    "From: https://discuss.pytorch.org/t/about-normalization-using-pre-trained-vgg16-networks/23560 \n",
    "*Usually if your use case stays in the same data domain, the mean and std won’t be that different and you can try to use the ImageNet statistics.\n",
    "I would recommend to use your own data statistics if you are dealing with another domain, e.g. medical images.*\n",
    "\n",
    "\n",
    "More models here: https://pytorch.org/docs/stable/torchvision/models.html\n",
    "\n",
    "If the models do not start to converge, try lowering the learning rate!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_VGG16_\n",
    "\n",
    "Currently getting validation f1 scores around 0.67. \n",
    "\n",
    "Now around 0.71 with one cycle policy.\n",
    "\n",
    "Surprisingly after quick testing the vgg16_bn (with BatchNorm layers) did not do as well? Maybe more to investigate here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    model = vgg16(pretrained=True).to(device)\n",
    "\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Linear(25088, 4096),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(4096, 2048),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(2048, 14),\n",
    "    ).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_RESNET_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    model = resnet18(pretrained=True).to(device)\n",
    "\n",
    "    for layer in model.children():\n",
    "        layer.requires_grad = False\n",
    "\n",
    "    model.fc = nn.Linear(512, 14).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    model = resnet34(pretrained=True).to(device)\n",
    "\n",
    "    for layer in model.children():\n",
    "        layer.requires_grad = False\n",
    "\n",
    "    model.fc = nn.Linear(512, 14).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    model = resnet50(pretrained=True).to(device)\n",
    "\n",
    "    for layer in model.children():\n",
    "        layer.requires_grad = False\n",
    "\n",
    "    model.fc = nn.Linear(2048, 14).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    model = resnet101(pretrained=True).to(device)\n",
    "\n",
    "    for layer in model.children():\n",
    "        layer.requires_grad = False\n",
    "\n",
    "    model.fc = nn.Linear(2048, 14).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    model = resnet152(pretrained=True).to(device)\n",
    "\n",
    "    for layer in model.children():\n",
    "        layer.requires_grad = False\n",
    "\n",
    "    model.fc = nn.Linear(2048, 14).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model or load an existing model from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "pos_weight = torch.from_numpy(label_pos_weights_for_loss).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "#criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# learning rate and momentum will be overriden by the scheduler\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, nesterov=True)\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=0.00001)\n",
    "\n",
    "# scheduler\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=0.01,\n",
    "    base_momentum=0.5,\n",
    "    max_momentum=0.95,\n",
    "    steps_per_epoch=len(train_dataloader),\n",
    "    epochs=n_epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths for model saving and loading\n",
    "\n",
    "# ResNet 101\n",
    "#model_save_path = '../data/resnet-valid-acc-aug-0.70.pth'\n",
    "#model_save_path = '../data/resnet-101-valid-acc-0.73-2.pth'\n",
    "\n",
    "#model_save_path = '../data/resnet-152-valid-acc-0.722.pth'\n",
    "#model_save_path = '../data/resnet-152-valid-acc-0.727.pth'\n",
    "\n",
    "# VGG16\n",
    "#model_save_path = '../data/vgg16-9epochs-valid-acc-0.66.pth'\n",
    "#model_save_path = '../data/vgg16-valid-acc-0.71.pth'\n",
    "\n",
    "# Whole model\n",
    "#model_whole_save_path = '../data/vgg16-7epochs-valid-acc-0.703.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plain model saving and loading (only state dictionary).\n",
    "#torch.save(model.state_dict(), model_save_path)\n",
    "#model.load_state_dict(torch.load(model_save_path, map_location=torch.device(device)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save an entire model (not just the state dict)\n",
    "#torch.save(model, model_whole_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an entire model (not just the state dict)\n",
    "#model = torch.load(model_whole_save_path)\n",
    "#model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is for trying to train all the layers...\n",
    "#for param in model.parameters():\n",
    "#    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a model from disk to continue training\n",
    "#model = torch.load('../data/vgg16-25epochs-64bs-lr0.01-valid-F1-0.683.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time tr_losses, val_losses, tr_scores, val_scores = \\\n",
    "    train(train_dataloader, valid_dataloader, model, optimizer, scheduler, criterion, device, \\\n",
    "          n_epochs=n_epochs, \\\n",
    "          verbose=False, \\\n",
    "          threshold=threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a model on disk to continue training later\n",
    "if True:\n",
    "    f1 = val_scores[-1]\n",
    "    model_whole_save_path = f'../data/vgg16-epochs{n_epochs}-bs{bs}-lr{lr}-valid-F1-{f1:.3}.pth'\n",
    "    #model_whole_save_path = f'../data/vgg16-epochs25|{n_epochs}-bs64|{bs}-lr0.01|{lr}-valid-F1-{f1:.3}.pth'\n",
    "    print(f'Saving model to {model_whole_save_path}')\n",
    "    torch.save(model, model_whole_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(valid_dataloader, model, criterion, device, threshold=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is for finding the optimal threshold.\n",
    "if False:\n",
    "    f1_scores = []\n",
    "    for threshold in np.arange(0.05, 1, 0.05):\n",
    "        _, f1 = evaluate(valid_dataloader, model, criterion, device, threshold=threshold)\n",
    "        f1_scores.append(f1)\n",
    "        print(f'threshold: {threshold}, f1 score: {f1}')\n",
    "\n",
    "    plt.plot(np.arange(0.05, 1, 0.05), f1_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show some images with predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    visualize_predictions(model, device, test_dataloader, n_to_show=5, threshold=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TP/FP/TN/FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_tpfptnfn = False\n",
    "img_label = 'baby'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if visualize_tpfptnfn:\n",
    "    visualize_true_positives(img_label, model, device, valid_dataloader, n_to_show=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if visualize_tpfptnfn:\n",
    "    visualize_false_positives(img_label, model, device, valid_dataloader, n_to_show=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if visualize_tpfptnfn:\n",
    "    visualize_true_negatives(img_label, model, device, valid_dataloader, n_to_show=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if visualize_tpfptnfn:\n",
    "    visualize_false_negatives(img_label, model, device, valid_dataloader, n_to_show=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if True:\n",
    "    # Predict\n",
    "    y_true, y_pred = predict(model, device, valid_dataloader)\n",
    "    np.save(f'../data/valid_true_labels.npy', y_true)\n",
    "    np.save(f'../data/valid_pred_labels.npy', y_pred)\n",
    "    \n",
    "    # Save classification report\n",
    "    with open(f'../data/valid_classification_report.txt', 'w') as file:\n",
    "        file.write(skm.classification_report(y_true, y_pred))\n",
    "    \n",
    "    # Save confusion matrix plot\n",
    "    labels = [k for k, v in get_class_map().items()]\n",
    "    visualize_confusion_matrix(y_true, y_pred, labels, f'../data/valid_confusion_matrix.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show classification report\n",
    "with open(f'../data/valid_classification_report.txt', 'r') as file:\n",
    "    report = ''.join(file.readlines())\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show confusion matrix plot\n",
    "IPython_Image(filename=f'../data/valid_confusion_matrix.png', width=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report results\n",
    "\n",
    "## Predict for testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH2 = '../test_data'\n",
    "DATA_PATH2 = '../data'\n",
    "IMAGE_PATH2 = f'{DATA_PATH2}/images'\n",
    "LABEL_PATH2 = f'{DATA_PATH2}/annotations'\n",
    "\n",
    "# Load testset\n",
    "if not os.path.isfile(f'{DATA_PATH2}/X_test_n{max_images_per_class}.dat'):\n",
    "    print('Loading test data from disk.')\n",
    "    X_test2, y_test2, _, _, _, _ = get_data(max_images_per_class=max_images_per_class, train_fr=1, IMAGE_PATH=IMAGE_PATH2, LABEL_PATH=LABEL_PATH2)\n",
    "    torch.save(X_test2, f'{DATA_PATH2}/X_test_n{max_images_per_class}.dat')\n",
    "    torch.save(y_test2, f'{DATA_PATH2}/y_test_n{max_images_per_class}.dat')\n",
    "    print(' - Done.')\n",
    "else:\n",
    "    print('Loading saved torch dump from disk.')\n",
    "    X_test2 = torch.load(f'{DATA_PATH2}/X_test_n{max_images_per_class}.dat')\n",
    "    y_test2 = torch.load(f'{DATA_PATH2}/y_test_n{max_images_per_class}.dat')\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    TransformingDataset(X_test2, y_test2, transforms=transformations['test']),\n",
    "    shuffle=True,\n",
    "    batch_size=bs)\n",
    "\n",
    "# Load our best model\n",
    "#model = torch.load('../data/vgg16-epochs20-bs64-lr0.01-valid-F1-0.692.pth')\n",
    "\n",
    "# Predict \n",
    "y_true, y_pred = predict(model, device, test_dataloader)\n",
    "\n",
    "# Save to disk\n",
    "np.savetxt(f'{DATA_PATH2}/results_pred.txt', y_pred, fmt='%d')\n",
    "np.savetxt(f'{DATA_PATH2}/results_true.txt', y_true, fmt='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show predictions\n",
    "with open(f'{DATA_PATH2}/results_pred.txt', 'r') as file:\n",
    "    report = ''.join(file.readlines())\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show true labels\n",
    "with open(f'{DATA_PATH2}/results_true.txt', 'r') as file:\n",
    "    report = ''.join(file.readlines())\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Adv ml",
   "language": "python",
   "name": "advml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
